{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53470e3-090d-4703-b49d-f4a3ca26ab6e",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "Tensors are a specilaized data structure that are very similar to arrays and matrices.\n",
    "\n",
    "In Pytorch, we use tensors to encode the inputs and outputs of a model, as well as the model's parameters.\n",
    "\n",
    "Tensors are similar to NumPy's ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data.\n",
    "\n",
    "Tensors are also optimized for automatic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598ff00-2935-4139-859d-d31ae8365f36",
   "metadata": {},
   "source": [
    "## Initializing a Tensor\n",
    "Tensors can be initialized in various ways. Here are some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b87e62-45da-4346-b620-e368c43d140f",
   "metadata": {},
   "source": [
    "### Directly from Data\n",
    "Tensors can be created directly from data. The data type is automatically inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2280fb3e-c759-4ef4-a2c9-bb1d3eea0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor x_data:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(f'Tensor x_data:\\n{x_data}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412823c2-4077-4739-997f-b51ed4e470b9",
   "metadata": {},
   "source": [
    "### From a NumPy array\n",
    "Tensors can be created from NumPy arrays (and vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327292a4-9130-4d62-a3ad-83776ab0a2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "Tensor from NumPy Array:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"NumPy Array:\\n{np_array}\\n\")\n",
    "print(f'Tensor from NumPy Array:\\n{x_np}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74f03ae-f76f-4d48-a54b-a429534b5d95",
   "metadata": {},
   "source": [
    "### From another tensor:\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43aa1b8a-8383-4073-b01f-c831f7b5f199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor:\n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tesnor:\n",
      " tensor([[0.2657, 0.1195],\n",
      "        [0.8898, 0.8610]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f'Ones Tensor:\\n {x_ones} \\n')\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) #overrides the datatype of x_data\n",
    "print(f'Random Tesnor:\\n {x_rand} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ec1fb5-2f28-4ea8-b9c1-5f0381b2cdda",
   "metadata": {},
   "source": [
    "### With random or constant values:\n",
    "`shape` is a tuple of tensor dimensions. In the functions bleow, it determines the dimensionality of the output tensor.\n",
    "\n",
    "A `tuple` stores multiple items in a single variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c6f02a-0f30-43eb-b60f-1d4b0c56a1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2529, 0.5051, 0.4882],\n",
      "        [0.7300, 0.3428, 0.1516]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,) # A tuple of tensor dimensions\n",
    "\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68ef1f-8902-4f29-b6a9-6692e3206882",
   "metadata": {},
   "source": [
    "## Attributes of a Tensor\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c37115-0e01-4e9d-968f-858ee5d4941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[0.5975, 0.1230, 0.7588, 0.5231],\n",
      "        [0.5801, 0.8028, 0.1855, 0.1036],\n",
      "        [0.5644, 0.2178, 0.7568, 0.1504]])\n",
      "\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4) # 3 x 4 (3 rows x 4 columns)\n",
    "print(f\"Tensor:\\n{tensor}\\n\")\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064997e-a17d-4872-9edc-8d8c6bc20742",
   "metadata": {},
   "source": [
    "## Operations on Tensors\n",
    "\n",
    "There are over 1200 tensor operations.\n",
    "\n",
    "Each of these operations can be run on the CPU and Accelerator such as CUDA, MPS, MTIA, or XPU.\n",
    "\n",
    "By deafult, tenors are created on the CPU. We need to explicitly move tensors to the accelerator using `.to` method (after checking for accelerator availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b14e023-2e4e-4b90-bb03-fbb2451ebf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerator is available\n",
      "Tensor moved to Accelerator \n",
      " tensor([[0.5975, 0.1230, 0.7588, 0.5231],\n",
      "        [0.5801, 0.8028, 0.1855, 0.1036],\n",
      "        [0.5644, 0.2178, 0.7568, 0.1504]], device='mps:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.accelerator.is_available():\n",
    "    print(f'Accelerator is available')\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())\n",
    "    print(f'Tensor moved to Accelerator \\n {tensor} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6829cf6-3b41-4960-ae4d-2cf591eb932d",
   "metadata": {},
   "source": [
    "### Standard numpy-like indexing and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa75c859-030f-418b-9661-4b23c8c22453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "Updated tensor: \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[...,-1]}\")\n",
    "tensor[:,1] = 0 # This will set all elements in column @ index 1 equal to 0\n",
    "print(f\"Updated tensor: \\n {tensor} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88debf0a-eb8a-4db1-8627-f6a94401f848",
   "metadata": {},
   "source": [
    "### Joining tensors\n",
    "You can use `torch.cat` to concatenate a sequence of tensors along a given dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c76661c-e22a-4392-aaee-38fb7e7a4c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Tensors: \n",
      " tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor,tensor,tensor], dim=1)\n",
    "print(f'Concatenated Tensors: \\n {t1} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b2fd6-2570-4dc3-9c8d-8b1a8a68bfca",
   "metadata": {},
   "source": [
    "### Arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc1e015c-98e6-4c7c-a423-490a91c4e248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c040d-d8b7-4ce2-b1b0-1c923cf61c1d",
   "metadata": {},
   "source": [
    "### Single-element tensors\n",
    "If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using `item()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d12da9e6-7dd9-4646-9faf-13d8899aab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406cd69-4fb5-446b-820a-a1b6dda864eb",
   "metadata": {},
   "source": [
    "### In-place operations\n",
    "Operations that store the result into one operand are called in-place.\n",
    "They are denoted by a `_` suffix. For example: `x.copy_(y)`, `x.t_()`, will change `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996cc281-7c3a-4bbc-be43-0852bd24b5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ee777-d3c3-4b15-a987-2f3cba5669ff",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
